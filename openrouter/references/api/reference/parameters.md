# API Parameters Documentation

## Overview

The OpenRouter API accepts various sampling parameters that control token generation. If parameters are omitted, OpenRouter applies defaults. Provider-specific parameters (like `safe_prompt` for Mistral) are passed directly to respective providers.

## Core Sampling Parameters

### Temperature
- **Key:** `temperature`
- **Type:** Float (0.0-2.0)
- **Default:** 1.0

Lower values lead to more predictable and typical responses, while higher values encourage more diverse and less common responses.

### Top P
- **Key:** `top_p`
- **Type:** Float (0.0-1.0)
- **Default:** 1.0

Constrains model choices to tokens whose cumulative probabilities reach a threshold. Lower values increase predictability; the default enables full token range consideration.

### Top K
- **Key:** `top_k`
- **Type:** Integer (0+)
- **Default:** 0

Restricts token selection to the K most likely options at each step. A value of 1 forces selection of the most probable token; default (disabled) considers all possibilities.

### Frequency Penalty
- **Key:** `frequency_penalty`
- **Type:** Float (-2.0 to 2.0)
- **Default:** 0.0

Controls repetition based on input frequency. Token penalty scales with the number of occurrences. Negative values encourage reuse.

### Presence Penalty
- **Key:** `presence_penalty`
- **Type:** Float (-2.0 to 2.0)
- **Default:** 0.0

Adjusts repetition likelihood for previously-used tokens. Token penalty does not scale with the number of occurrences.

### Repetition Penalty
- **Key:** `repetition_penalty`
- **Type:** Float (0.0-2.0)
- **Default:** 1.0

Reduces input token repetition. Higher values decrease repetition but excessive values may harm coherence.

### Min P
- **Key:** `min_p`
- **Type:** Float (0.0-1.0)
- **Default:** 0.0

Sets minimum token probability relative to the most likely token.

### Top A
- **Key:** `top_a`
- **Type:** Float (0.0-1.0)
- **Default:** 0.0

Filters tokens based on sufficiently high probabilities relative to the best option.

## Generation Control Parameters

### Seed
- **Key:** `seed`
- **Type:** Integer
- **Note:** Determinism not guaranteed for all models

Enables deterministic sampling -- identical requests with same seed and parameters yield consistent results.

### Max Tokens
- **Key:** `max_tokens`
- **Type:** Integer (1+)

Sets upper limit on response token count. Cannot exceed context length minus prompt length.

### Stop
- **Key:** `stop`
- **Type:** Array

Halts generation upon encountering specified tokens.

## Advanced Parameters

### Logit Bias
- **Key:** `logit_bias`
- **Type:** Map (JSON object)

Maps token IDs to bias values (-100 to 100). The bias is added to the logits generated by the model prior to sampling.

### Logprobs
- **Key:** `logprobs`
- **Type:** Boolean

Returns log probabilities of output tokens when enabled.

### Top Logprobs
- **Key:** `top_logprobs`
- **Type:** Integer (0-20)

Specifies count of most likely tokens with log probabilities at each position. Requires `logprobs: true`.

## Output Formatting

### Response Format
- **Key:** `response_format`
- **Type:** Map

Set to `{ "type": "json_object" }` for JSON mode, guaranteeing valid JSON output. Pair with explicit model instructions.

### Structured Outputs
- **Key:** `structured_outputs`
- **Type:** Boolean

Enables structured output using JSON schema response format.

### Verbosity
- **Key:** `verbosity`
- **Type:** Enum (low, medium, high, max)
- **Default:** medium

Controls response detail level. For Anthropic models, maps to `output_config.effort`; 'max' requires Claude 4.6 Opus or later.

## Tool Integration

### Tools
- **Key:** `tools`
- **Type:** Array

Follows OpenAI's tool calling format; non-OpenAI providers receive transformed requests.

### Tool Choice
- **Key:** `tool_choice`
- **Type:** Array

Controls tool invocation: 'none' (no tools), 'auto' (model decides), 'required' (must call), or specific tool specification.

### Parallel Tool Calls
- **Key:** `parallel_tool_calls`
- **Type:** Boolean
- **Default:** true

Enables simultaneous function calls when true; sequential when false.
